{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regular Expressions\n",
    "During this workshop we'll cover...\n",
    "* The purpose,\n",
    "* The methods,\n",
    "* The syntax, and\n",
    "* The strategies for using regex.\n",
    "\n",
    "We'll use Python's version of regex (the `re` module) for today's exercise.  Regex is available in pretty much all major scripting and programming languages.  We'll conclude the workshop with a practical application.  During the PracApp we'll use the `pandas` module.  Since pandas is not the focus of the workshop I've provided skeleton scripts to enable those without that experience.  \n",
    "\n",
    "##    The purpose of regex\n",
    "Regex was developed in the 1950s as a method to characterize sub-strings within a set of text.  It has a formal theoretical definition that draws from computer science, set theory, and language theory.  It was implemented as early as the 1960s, and has progressively gained popularity as a way to conduct text search within a document.  Most compiled and interpreted languages have access to regex functionality through a library (standard or otherwise) or within a base distribution.  Syntax and functionality can vary from one language to the next, but core tasks and strategies are consistent.\n",
    "\n",
    "Our modelers use regex to extract structure from unstructured text data.  It is the ideal tool to address tasks like finding and extracting URLs, email addresses, phone numbers, or other such information from a set of documents within a corpus.  To do this it searches, character by character, through a text string attempting to match at each step.  It is especially useful in web-scraping applications that have to be tailored to a specific purpose.  Also of note, the `nltk` module within Python includes tokenizing objects that directly reference their own version of regex.\n",
    "\n",
    "##  The methods of the [`re` module](https://docs.python.org/2/library/re.html)\n",
    "Several methods and constants are available.  We'll discuss a few here.  This section is provided as a reference for you to use during subsequent hands-on sections.\n",
    "\n",
    "First, the **`re.compile()`** method creates a RegExObject that can be useful when one intends to use the results of the same pattern multiple times within a script.  The other methods that we'll cover today can be accessed directly from the `re` module, or from a RegExObject.  Creating a RegExObject is good practice for all but the simplest scripts.  As the name implies, it can speed computational time for complex data processing scripts.\n",
    "\n",
    "The **`re.search()`** and **`re.match()`** methods are used to find a matching substring within a document.  `re.match()` will return a match object if the pattern is found at the ***beginning*** of the text, while `re.search()` will go through the ***entire*** text until it finds a matching substring or reaches the end.  `re.search()` will only return the first match encountered (left to right).  \n",
    "\n",
    "The **`re.findall()`** and **`re.finditer()`** methods are useful for finding all of the matching (non-overlapping) substrings; as opposed to merely the first.  `re.findall()` returns a python list with the results, while `re.finditer()` returns an iterable of the match objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The match returns: None\n",
      "\n",
      "The search returns: <_sre.SRE_Match object at 0x02DC4BB8>\n",
      "\n",
      "The findall returns: \n",
      "['123', '456']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "myStr = \"A simple test string with numbers in it like these: 123, 456.\"\n",
    "myRE = re.compile(r'[1-9]{3}') # This pattern is looking for three numeric characters in succession.\n",
    "\n",
    "mtch = myRE.match(myStr)\n",
    "srch = myRE.search(myStr)\n",
    "\n",
    "fndall = myRE.findall(myStr)\n",
    "\n",
    "print('The match returns: ' + str(mtch) + '\\n')\n",
    "\n",
    "print('The search returns: ' + str(srch) + '\\n')\n",
    "\n",
    "print('The findall returns: ')\n",
    "print(fndall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't the `match()` return a result?   By the way, when `match()` or `search()` fail they return a `NoneType` object.  \n",
    "\n",
    "What's up with the `search()` return?   How would we get access to the actual result?\n",
    "\n",
    "What do you think `finditer()` would do?\n",
    "\n",
    "The match objects returned by `match()`, `search()`, and `finditer()` have properties that allow access to, among other things, the matched string; as in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "# Please note that you must execute the code cell above this one in order for this one to work.\n",
    "\n",
    "print(srch.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other properties give one access to the starting and ending position of the match (useful for data cleaning), and other such valuable attributes. \n",
    "\n",
    "**Flags** are options of the methods listed above that alter the behavior of the match.  One example is the **`re.IGNORECASE`** flag that, as the name implies, matches alphabetic characters without considering the capitalization.  Another is the **`re.DOTALL`** flag, that changes the behavior of the (**.**) special character to include newlines, as seen below.\n",
    "\n",
    "##  The syntax\n",
    "\n",
    "A regex pattern, or merely a regex, is composed of literals, metacharacters, and special characters.  **Literals**, as the name implies, are meant to match the exact characters as they appear.  **Metacharacters** are used to construct a match for broad categories of things like whitespace, words, or structured groups.  \n",
    "\n",
    "Many cheatsheets are available online, like [this one](https://www.debuggex.com/cheatsheet/regex/python).  The simplest **special characters** exist that enable quick access to large classes of text.  For example, a single period (**`.`**) will match any single character except a newline (unless the DOTALL flag is specified).  \n",
    "\n",
    "The primary metacharacter is the backslash (\\\\).  The \\\\ will either escape a special character allowing it to be matched as a literal, or denote a character class or assertion (thus converting a literal into a special). A couple of the interesting special characters are presented below.  See the myriad cheatsheets for a more complete listing (like the one referenced above).\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>\n",
    "Special Character\n",
    "</th>\n",
    "<th>\n",
    "Matches\n",
    "</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    ".\n",
    "</td>\n",
    "<td>\n",
    "Any character except a new line\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "*\n",
    "</td>\n",
    "<td>\n",
    "Zero or more of the previous token... use with caution\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "+\n",
    "</td>\n",
    "<td>\n",
    "One or more of the previous token\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "{2}\n",
    "</td>\n",
    "<td>\n",
    "Exactly 2 of the previous token\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\\d\n",
    "</td>\n",
    "<td>\n",
    "One digit character\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\\s\n",
    "</td>\n",
    "<td>\n",
    "One whitespace character\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\\w\n",
    "</td>\n",
    "<td>\n",
    "One word character; that is, one alpha-numeric\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\\b\n",
    "</td>\n",
    "<td>\n",
    "A word boundary\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Using the syntax we've covered so far, can you construct a regex that will find the email address in the given string?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m003826@gbsmg.edu\n"
     ]
    }
   ],
   "source": [
    "myStr = \"The email address in question is constructed as the letter 'm' followed by 6 digits, followed by '@' followed by some number of alpha-numerics, followed by '.edu'.  One example is m003826@gbsmg.edu which is the string we want to find.\"\n",
    "\n",
    "yourRE = r\"\" # Put your regex in the quotes here.\n",
    "\n",
    "yourObj = re.compile(yourRE) # You could skip this step and go straight to yourSrch = re.search(yourRE, myStr) if you really wanted\n",
    "\n",
    "yourSrch = yourObj.search(myStr)\n",
    "\n",
    "print(yourSrch.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've probably realized, there are many ways to write this expression to find what we're looking for.  Using only what we've talked about so far produces a rather brute force solution.  It does, however, have the advantage of working.  If you've read ahead and built something a little more subtle it has the advantage of being a more readable.  \n",
    "\n",
    "We have two more syntax concepts to cover.  The first is that of **groups**.  Groups collect tokens together, and allow ordering.  As you may have guessed, the `.group()` attribute above allows access to invidual groups within a regex (the 0 index indicates the whole matched string).  Groups are denoted by parenthesis; as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accidently\n"
     ]
    }
   ],
   "source": [
    "myStr = \"If I'm parsing natural language, and want to find common accidently misspelled words.\"\n",
    "### If we're looking for accidentally, but want to include known misspellings...\n",
    "myRE = \"ac{1,2}ident(al)?ly\" # Should match accidentally, accidently, acidentally\n",
    "\n",
    "print(re.search(myRE, myStr).group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the curly braces `{}` and question mark `?` above; they're different kinds of **quantifiers**.  Quantifiers are often used in conjunction with groups as I've done here.  The `?` matches 0 or 1 of the preceding token.  By default quantifiers are **greedy**, meaning that they'll match as many characters as possible.  That is why `.*` can be problematic without additional conditions applied.  You can specify **lazy** match with the addition of a question mark `?` after the quantifier (as in, `.*?`).  \n",
    "\n",
    "It's also worth noting that the question mark is a special special character in that its interpretation depends on the context.  It can be a quantifier or a lazy specification, but it could also have other meanings (see look arounds below).  \n",
    "\n",
    "Now let's apply the same technique to searching tweets for laughing.  The `myStr` variable below is a list of notional tweets, in which we'll try to find and match on different ways that a person might record that they're laughing.  \n",
    "\n",
    "**Hint** A pipestem `|` is recognized as a parallel, 'or' match.  This is known as **alternation** because you're specifying alternatives.  For this exercise you'll want to be careful how you contruct the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOL\n",
      "\n",
      "ha\n",
      "\n",
      "Ha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myStr = ['LOL, that was sooooo funny!', 'That video made me laugh... hahaha #funny', 'Ha! I loved it!']\n",
    "\n",
    "yourRE = r\"\" # Type a regex in the parenthesis that will capture the laughter above.\n",
    "yourObj = re.compile(yourRE, re.IGNORECASE)\n",
    "\n",
    "for s in myStr:\n",
    "    print yourObj.search(s).group(0) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that we're using a raw string now: `r\"\"`.  That's because Python interprets a non-raw string `\\b` as a backspace, which doesn't work for us.  You can start to see how we would go about using an iterable object like a list or a pandas dataframe/series to pull interesting things out of text fields.  \n",
    "\n",
    "The last major concept we'll cover is looking around.  **Look arounds** are a powerful way to find sub-strings based on context without including the context in the match.  There are four kinds of look arounds, summarized in the table below.  Replace the ellipsis with the appropriate regex. \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>\n",
    "Look around group\n",
    "</th>\n",
    "<th>\n",
    "Asserts...\n",
    "</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "(?=...)\n",
    "</td>\n",
    "<td>\n",
    "Positive look ahead\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "(?!...)\n",
    "</td>\n",
    "<td>\n",
    "Negative look ahead\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "(?&lt;=...)\n",
    "</td>\n",
    "<td>\n",
    "Positive look behind\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "(?&lt;!...)\n",
    "</td>\n",
    "<td>\n",
    "Negative look behind\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "A look around adds another condition for a match that considers substrings before and after the currently considered substring.  In the example below we're looking for a username contained within an email address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rlantz\n"
     ]
    }
   ],
   "source": [
    "myStr = \"Suppose my email address is contained within a text string, rlantz@novetta.com, then we're trying to find my username.\"\n",
    "\n",
    "myRE = r\"(\\w*(?=@))\"\n",
    "\n",
    "myObj = re.compile(myRE, re.I)\n",
    "\n",
    "print myObj.search(myStr).group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another notable is that Python's regex engine needs to know how many characters to check in a look behind.  For that reason you can't use quantifiers in a look behind.  Alternation requires that the alternatives be of the same length.  \n",
    "\n",
    "Now your turn.  This regex will incorporate many of the concepts that we've covered; such as escape characters, quantifiers, groups, and look arounds.  Suppose that you know a 10 digit account number is immediately followed by the individual's account balance.  Construct a regex that will match the account number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9876543201\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "myStr = \"My phone number is 1023456789, and my account information is 9876543201 $250.00 or something like that.\"\n",
    "\n",
    "# For the purpose of this exercise, you don't need to worry about commas within an account balance.\n",
    "\n",
    "yourRE = r\"\"\n",
    "\n",
    "yourObj = re.compile(yourRE, re.I)\n",
    "\n",
    "print(yourObj.search(myStr).group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The strategies\n",
    "\n",
    "The following are questions that I've found to be helpful when approaching a text parsing or search problem.  \n",
    "\n",
    "* What makes the intended matching string unique?  \n",
    "    * Deconstruct the elements that make it unique, and list the syntax associated with each.\n",
    "    * Order and group the listed regexes as appropriate.\n",
    "* Are you attempting to extract the intended match, or merely check for its presence?\n",
    "* Is it possible that more than one intended match will occur, and do you want to return all of them?\n",
    "* Are there elements consistently occuring before or after the intended match?\n",
    "* Finally (admittedly not a question) be prepared for trial and error; a testing regimen is a must.\n",
    "\n",
    "Recently many regex [testers](https://www.debuggex.com/?flavor=python) have arisen making it relatively easy to check your regex against a test string.  While helpful for quick checks, it's possible that an online tester will return inconsistent results (e.g., the raw string problem).  For important applications, I recommend writing your own regex test script in your language of choice.\n",
    "\n",
    "Finally, if you're looking for a regex tutorial that is not specific to Python, I recommend [this one](http://www.regular-expressions.info/tutorial.html). \n",
    "\n",
    "# Practical Application\n",
    "\n",
    "Using the dataset and sample scripts provided construct regexs that perform the following tasks:\n",
    "\n",
    "* Match the email addresses in the **`fi_fi_info`** field.\n",
    "* Match the phone numbers in the **`fi_fi_info`** field.\n",
    "* Match and remove the account numbers that have leaked into the **`receiver_fi_info`** field.\n",
    "\n",
    "After confirming that the respective counts are correct, open the .csv file to spot check some of your results.  \n",
    "\n",
    "The first code block is a preliminary step that will read in your data.  When prompted you should point to the \"fm_workshop1.csv\" dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read is complete\n",
      "C:/Users/rlantz/Documents/regex-training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDX</th>\n",
       "      <th>tid</th>\n",
       "      <th>receiver_fi_info</th>\n",
       "      <th>fi_fi_info</th>\n",
       "      <th>Results1</th>\n",
       "      <th>Results2</th>\n",
       "      <th>Results3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.300000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.140000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.160000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.060000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.210000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDX           tid receiver_fi_info fi_fi_info Results1 Results2 Results3\n",
       "0    1  6.300000e+11              NaN        NaN     None     None     None\n",
       "1    2  3.140000e+11              NaN        NaN     None     None     None\n",
       "2    3  3.160000e+11              NaN        NaN     None     None     None\n",
       "3    4  2.060000e+11              NaN        NaN     None     None     None\n",
       "4    5  5.210000e+11              NaN        NaN     None     None     None"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this first\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import Tkinter, tkFileDialog\n",
    "\n",
    "def getFP():\n",
    "    root = Tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    fp = tkFileDialog.askopenfilename(parent = root, title = \"Choose a File\")\n",
    "    return fp\n",
    "\n",
    "myFP = getFP()\n",
    "myData = pd.read_csv(myFP)\n",
    "\n",
    "resFP = myFP[:myFP.rfind('/')]\n",
    "\n",
    "myData['Results1'] = 'None'\n",
    "myData['Results2'] = 'None'\n",
    "myData['Results3'] = 'None'\n",
    "\n",
    "print(\"Data read is complete\")\n",
    "\n",
    "print(resFP)\n",
    "myData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190\n"
     ]
    }
   ],
   "source": [
    "# Complete this code and run it for the first exercise\n",
    "\n",
    "### Exercise 1. Pull the email addresses and place the results in 'Results1' ###\n",
    "\n",
    "yourRE = r\"\" # Construct a regex that will match email addrsses\n",
    "yourObj = re.compile(yourRE)\n",
    "cntEmails = 0\n",
    "\n",
    "for i, r in enumerate(myData['fi_fi_info']):\n",
    "    if type(r) == str:\n",
    "        if yourObj.search(r):\n",
    "            res = yourObj.search(r).group(0) \n",
    "            myData.Results1.iat[i] = res\n",
    "            cntEmails += 1 \n",
    "\n",
    "print(cntEmails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190\n"
     ]
    }
   ],
   "source": [
    "# Complete this code and run it for the second exercise\n",
    "\n",
    "### Exercise 2. Pull the phone numbers and place the results in 'Results2' ###\n",
    "\n",
    "yourRE = r\"\" # Construct a regex that will match phone numbers\n",
    "yourObj = re.compile(yourRE)\n",
    "cntPhs = 0\n",
    "\n",
    "for i, r in enumerate(myData['fi_fi_info']):\n",
    "    if type(r) == str:\n",
    "        if yourObj.search(r):\n",
    "            res = yourObj.search(r).group(0) \n",
    "            myData.Results2.iat[i] = res   \n",
    "            cntPhs += 1 \n",
    "\n",
    "print(cntPhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "     IDX           tid receiver_fi_info  \\\n",
      "466  467  3.030000e+11              NaN   \n",
      "542  543  1.120000e+12              NaN   \n",
      "600  601  2.190000e+11              NaN   \n",
      "845  846  2.270000e+11              NaN   \n",
      "995  996  1.210000e+11              NaN   \n",
      "\n",
      "                                            fi_fi_info  \\\n",
      "466  ATTN: Christine Jenkins, Phone: 370-(733)108-7...   \n",
      "542  ATTN: Steven Kennedy, Phone: 7-(172)115-7146 E...   \n",
      "600  ATTN: Matthew Young, Phone: 36-(833)603-1795, ...   \n",
      "845  ATTN: Evelyn Stephens, Phone: 20-(709)181-4335...   \n",
      "995  ATTN: Jane Warren, Phone: 62-(435)302-8328, Em...   \n",
      "\n",
      "                    Results1           Results2 Results3  \n",
      "466   cjenkinsbj@samsung.com  370-(733)108-7400     None  \n",
      "542  skennedyj2@yolasite.com    7-(172)115-7146     None  \n",
      "600          myoungdc@wp.com   36-(833)603-1795     None  \n",
      "845  estephenslj@mozilla.org   20-(709)181-4335     None  \n",
      "995   jwarreno1@amazon.co.jp   62-(435)302-8328     None  \n",
      "           IDX           tid  \\\n",
      "367        368  1.030000e+11   \n",
      "2124      2125  9.080000e+11   \n",
      "7397      7398  1.010000e+12   \n",
      "129035  129036  1.110000e+12   \n",
      "\n",
      "                                         receiver_fi_info fi_fi_info Results1  \\\n",
      "367     ATTN: Anthony Reid, 51-(197)807-7687, Phone: M...        NaN     None   \n",
      "2124    ATTN: Angela Washington, 380-(703)417-2110, Ph...        NaN     None   \n",
      "7397    ATTN: Steven Riley, 7-(860)450-8279, AccNum , ...        NaN     None   \n",
      "129035  ATTN: Antonio Watson, 880-(141)488-5734, Phone...        NaN     None   \n",
      "\n",
      "       Results2          Results3  \n",
      "367        None     1234543211234  \n",
      "2124       None  12345 4321 12345  \n",
      "7397       None    1234 4321 1234  \n",
      "129035     None      123 4321 123  \n"
     ]
    }
   ],
   "source": [
    "# Complete this code and run it for the third exercise\n",
    "\n",
    "### Exercise 3. Pull and clean the account numbers and place them in 'Results3' ###\n",
    "\n",
    "yourRE = r\"\" # Construct a regex that will match account numbers\n",
    "yourObj = re.compile(yourRE)\n",
    "cntAccts = 0\n",
    "\n",
    "for i, r in enumerate(myData['receiver_fi_info']):\n",
    "    if type(r) == str:\n",
    "        if yourObj.search(r):\n",
    "            res =  yourObj.search(r).group(0) \n",
    "            myData.Results3.iat[i] = res\n",
    "            myData.receiver_fi_info.iat[i] = r.replace(res, \"\")\n",
    "            cntAccts += 1 \n",
    "\n",
    "print(cntAccts)\n",
    "\n",
    "myData.to_csv(resFP + \"/Workshop1_Results.csv\")\n",
    "print(myData[myData.fi_fi_info.notnull()].head())\n",
    "print(myData[myData.Results3 != 'None'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
